{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be06998-d3c5-4fa8-985c-07249e7c6c78",
   "metadata": {},
   "source": [
    "# Predicting Airbnb Price with Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90e20d-5594-4b3f-b6ba-3ccb8e9bf652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each report should include the following sections:\n",
    "#     Title\n",
    "#     Introduction\n",
    "#     Methods and Results\n",
    "#     Discussion\n",
    "#     References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e20d37-9d20-4929-a2f0-77d7019f3bd7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "1. Relevant background information on Airbnb; lay out the basic knowledge needed to understand the rest of the project (can do this later?)\n",
    "2. Question\n",
    "3. Describe dataset used to address question\n",
    "4. Align question with existing literature (2 scientific publicatons, listed below). You can format links [like this](https://docs.google.com/document/d/1dLtaAEjd5Tk2_6ZmR5hZoDo08JzhrnGkun8D0c2D3W0/edit?tab=t.87371pud50w6#heading=h.g5nne0jxfmlg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30993725-dabf-4660-9c9d-dce36c90c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries & Packages\n",
    "library(tidyverse)\n",
    "library(mltools)\n",
    "library(rsample)\n",
    "library(glmnet)\n",
    "\n",
    "library(leaps) #regsubsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564caa2e-8dc2-47f1-917c-59710536058f",
   "metadata": {},
   "source": [
    "## Methods and Results\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "To begin our analysis, we start by reading our data, with modfications to keep it tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581ad4a-fb75-4e60-b36c-82e1c0d5512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "# Contributor: Marcus (modified read function)\n",
    "\n",
    "# Function to format & read data: \n",
    "# select vars from dataset and add city name + if it's weekend data\n",
    "tidy_data <- function(path, cityName, isWeekend) {\n",
    "    data <- read_csv(path, show_col_types = FALSE) %>%\n",
    "        select(-...1, -attr_index, -attr_index_norm, -rest_index, -rest_index_norm)\n",
    "    data$room_type <- as.factor(data$room_type)\n",
    "    data$city <- as.factor(cityName)\n",
    "    data$isWeekend <- as.logical(isWeekend)\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "# Import and format data with tidy_data()\n",
    "london_weekdays <- (tidy_data(\"data/london_weekdays.csv\", \"London\", 0))\n",
    "london_weekends <- (tidy_data(\"data/london_weekends.csv\", \"London\", 1))\n",
    "rome_weekdays <- (tidy_data(\"data/rome_weekdays.csv\", \"Rome\", 0))\n",
    "rome_weekends <- (tidy_data(\"data/rome_weekends.csv\", \"Rome\", 1))\n",
    "budapest_weekdays <- (tidy_data(\"data/budapest_weekdays.csv\", \"Budapest\", 0))\n",
    "budapest_weekends <- (tidy_data(\"data/budapest_weekends.csv\", \"Budapest\", 1))\n",
    "\n",
    "# Merge all the data together\n",
    "data <- rbind(london_weekdays, london_weekends, rome_weekdays, rome_weekends, budapest_weekdays, budapest_weekends)\n",
    "\n",
    "# View the head and tail of the data\n",
    "head(data, 3)\n",
    "tail(data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b20c5e-d7f8-4cf0-bd31-507972bf5e40",
   "metadata": {},
   "source": [
    "Our data above appears to be in a tidy format, with minor inconsistencies to how booleans are represented. Otherwise, the variables have their correct representations. \n",
    "\n",
    "Let's go through an EDA checklist:\n",
    "\n",
    "## Below is copied from Marcus_Project\n",
    "\n",
    "- Packaging (& Wrangling as needed)\n",
    "- Head and tail of data (presented in a tidy format)\n",
    "- Check for NA values\n",
    "- Check n's and summary statistics\n",
    "- Plot visualizations for variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add969a-5534-44bb-94a6-ac4af131821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "\n",
    "# Packaging\n",
    "str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec98ab-4dc5-4843-845b-41e7f544029c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Main developer: Zahra\n",
    "\n",
    "# Check for missing/NA values\n",
    "anyNA(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0b364-5feb-4070-a09e-8b1e610afc13",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "\n",
    "# Compute summary statistics & check numbers\n",
    "dim(data)\n",
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e893a-b474-42ef-8e9b-a5968b113f9f",
   "metadata": {},
   "source": [
    "From the above summary statistics, we note the presence of outliers in `realSum` with a max of `15499.89`, which is much higher than the mean of `268.47`. \n",
    "\n",
    "A histogram of `realSum` will help visualize the distribution of our response and to remove outliers, to better understand possible relationships between `realSum` and the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46ac28-88ee-4618-ad5a-6d04790d1e1d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "\n",
    "# Plot a histogram of our response\n",
    "options(repr.plot.width = 8, repr.plot.height = 5)\n",
    "\n",
    "realSum_hist <- data %>%\n",
    "    ggplot(aes(x=realSum)) +\n",
    "    geom_histogram() +\n",
    "    labs(title=\"Histogram of Airbnb Prices\", x=\"Total Airbnb Price (Euros)\", y=\"Count\") +\n",
    "    theme(axis.text = element_text(size = 16), \n",
    "          axis.title = element_text(size = 16),\n",
    "         title=element_text(size = 20))\n",
    "\n",
    "realSum_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3f60b-6c09-40ed-93c9-4881efb0846c",
   "metadata": {},
   "source": [
    "Above, we clearly have large outliers in `realSum`. Let's filter the data to remove `realSum` above 1000 euros. In addition, lets plot the mean, and the 95th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db38c7-678c-42d5-9e18-e0f42b6e7704",
   "metadata": {},
   "source": [
    "It appears that our response data is very right skewed. 95% of Airbnb price listngs fall below ~`640`, with the average at around `280`. The threshold of `1000` still covers over 95% of listings, and thus is suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb94d59-809d-4e05-8886-b5d4c77ab5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "\n",
    "data_filt <- data %>% \n",
    "    filter(realSum < 1000)\n",
    "\n",
    "realSum_hist_filt <- data_filt %>%\n",
    "    ggplot(aes(x=realSum)) +\n",
    "    geom_histogram() +\n",
    "    geom_vline(xintercept=mean(data$realSum), color = \"red\") +\n",
    "    geom_vline(xintercept=quantile(data$realSum, 0.95), color = \"blue\") +\n",
    "    scale_x_continuous(breaks=seq(0, 1000, 100)) +\n",
    "    ggtitle(\"Histogram of Airbnb Prices < 1000\\nwith 95% threshold (blue) and mean price (red)\") +\n",
    "    labs(x=\"Total Airbnb Price\", y=\"Count\") +\n",
    "    theme(axis.text = element_text(size = 15), \n",
    "          axis.title = element_text(size = 15),\n",
    "         title=element_text(size = 16))\n",
    "    \n",
    "\n",
    "realSum_hist_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653326-d5a2-4763-95f6-ff3b4a4414ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Main developer: Matthew\n",
    "\n",
    "# Filters rows with N/A from the data\n",
    "data <- drop_na(data)\n",
    "\n",
    "#Altering columns to correct object types and filtering outliers\n",
    "tidy_data <-\n",
    "    data %>%\n",
    "    mutate(   #change columns into correct object types\n",
    "            across(c(room_type,city),as.factor),\n",
    "            across(c(multi,biz,isWeekend),as.logical)\n",
    "    ) %>%\n",
    "    group_by(city) %>%\n",
    "    filter(  #filtering outliers from each city by removing listing with prices that lies at the upper 5%\n",
    "        realSum <= quantile(realSum, 0.95, na.rm = TRUE)) %>%\n",
    "    ungroup()\n",
    "\n",
    "#To examine the distribution of listing prices in different cities through a boxplot\n",
    "city_listing_plot <-\n",
    "    tidy_data %>%\n",
    "    ggplot() +\n",
    "    geom_boxplot(aes(x=city,y=realSum,fill=city))+\n",
    "    ggtitle(\"Distribution of listing prices in different cities\")+\n",
    "    xlab(\"Cities\")+\n",
    "    ylab(\"Listing prices (EUR)\")+\n",
    "    stat_summary(aes(x=city, y=realSum),\n",
    "        fun = mean, geom = \"point\", colour = \"yellow\", \n",
    "        shape = 18, size = 5\n",
    "    ) +\n",
    "    theme(\n",
    "        text = element_text(size = 12),\n",
    "        plot.title = element_text(face = \"bold\"),\n",
    "        axis.title = element_text(face = \"bold\")\n",
    "    )\n",
    "city_listing_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8454310-7010-42e4-b9aa-c0e132a303c7",
   "metadata": {},
   "source": [
    "The box plot above that shows the distribution of listing prices across Budapest, London and Rome, it helps with the question as it allows one to see how the listing prices varies between cities.\n",
    "\n",
    "Starting with Budapest, it has the smallest variability in its distribution as well as the lowest median and mean. London, has the largest variability in its distribution and higher median and mean. Lastly, Rome has a variability in its distribution of listing prices thats relatively larger than Budapest as well a larger median and mean than Budapest but lower than London.\n",
    "\n",
    "Budapest and Rome shares a relatively similar distribution, median and mean of listing prices to one another, but London's wider distribution and higher median and mean may affect the goodness of fit of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee8242-5e97-47da-a112-d2e531038711",
   "metadata": {},
   "source": [
    "Next, [describe more plots here]\n",
    "\n",
    "> Marcus: I'm not sure if other plots of the raw data are relevant, since we plan to use forward selecton\n",
    "\n",
    "## END OF BASIC EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed76d4-f706-446a-a147-addffc8dfe4d",
   "metadata": {},
   "source": [
    "## Analysis Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e56e9-064b-4f1d-9884-18cd0badaace",
   "metadata": {},
   "source": [
    "Since we are analyzing a prediction question, it's important that we separate the data into testing and training sets to prevent double-dipping and to get an accurate understanding of the our model's scalability. The rsample package will help us for this task. We will use initial_split() to randomly split our dataset, with 70% for training use. We will use the training() and testing() functions to extract the training and testing data respectively. \n",
    "\n",
    "### Training: \n",
    "We will only use the training dataset here. We have 16 variables in our dataset that could be possible predictors of Airbnb listing price. We can use statistical variable selection process to determine which factors may be most useful in predicting our response. We can decide between subset selection methods (stepAIC() and regsubset()) and regularization methods (LASSO and Ridge). Regularization accounts for model complexity to better protect against overfitting, thus making it more applicable for predictive uses. Since LASSO is able to zero-out coefficients, we will use it to decide which variables are not included in the model.\n",
    "\n",
    "In order to use LASSO effectively, we must first find the best penalty term - the one that minimizes prediction error on unseen data. We can use cross validation to find this optimal value using the glmnet package. We will create a cross-validation model that utilizes LASSO, then select the lambda with the lowest MSE. We can also extract the coefficients from this model to see which variables have been selected and their relative association to realSum.\n",
    "\n",
    "\n",
    "### Testing:\n",
    "We will only use the testing dataset here. With our model completed, we can move on to predictions. We will use predict() with our cross-validation LASSO model, our selected penalty term, and our testing dataset to generate predicted values for realSum. \n",
    "\n",
    "### Evaluate Results:\n",
    "With our actual and predicted values, we can calculate the root-mean squared error using rmse() (from mltools) and examine its magnitude. A lower RMSE indicates that our model is good at predicting realSum values. We can use plot() with our predicted and actual values as a visual aid of our model's performance. We can evaluate the simplicity of our model by seeing how many variables are use as predictors compared to the total number of variables in the dataset. Finally, we will create a plot of our residuals (plot()) and a QQplot (qqnorm()) to ensure our assumptions for a linear model aren't violated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8032a7-ea33-44fc-b248-526b6834d80f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfd70d-1121-4806-809f-2535ef30267e",
   "metadata": {},
   "source": [
    "### Using LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25309788-1e37-44ef-9874-1bbff63e01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1515)\n",
    "data_split <- initial_split(data_filt, prop = 0.7, strata = realSum)\n",
    "training_data <- training(data_split)\n",
    "testing_data <- testing(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f9a37-06da-4338-8fd0-03f67c9e39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs <- model.matrix(realSum ~ .  - 1, data = training_data)[, -1]\n",
    "y_vals <- training_data$realSum\n",
    "cv_lasso <- cv.glmnet(inputs, y_vals, alpha = 1)\n",
    "best_lambda <- cv_lasso$lambda.min\n",
    "beta_lasso <- coef(cv_lasso, s = \"lambda.min\")\n",
    "\n",
    "summary(cv_lasso)\n",
    "best_lambda\n",
    "beta_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd1b95-5ae3-4956-98f5-1c5be3129424",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inputs <- model.matrix(realSum ~ .  - 1, data = testing_data)[, -1]\n",
    "actuals <- testing_data$realSum\n",
    "predictions <- predict(cv_lasso, s = best_lambda, newx = new_inputs)\n",
    "\n",
    "rmse <- rmse(actuals, predictions)\n",
    "rmse\n",
    "# plot(actuals, predictions, main = \"Actual vs Predicted\", xlab = \"Actual\", ylab = \"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6bdc2e-b15f-4c7a-b8f1-347f0fc18dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals <- actuals - predictions\n",
    "# plot(predictions, residuals,\n",
    "#      main = \"Residuals vs Fitted (Predicted)\",\n",
    "#      xlab = \"Fitted values\", ylab = \"Residuals\",\n",
    "#      pch = 19, col = \"steelblue\")\n",
    "# abline(h = 0, col = \"red\", lwd = 2)\n",
    "# qqnorm(residuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d87c7-de3d-476a-a071-4f9218d5b6f0",
   "metadata": {},
   "source": [
    "### had a mental breakdown from the rmse.... using regsubsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df4277-b844-4e0d-909f-5a05dc5ec75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regfit_full <- regsubsets(realSum ~ ., data = training_data, nvmax = 16, method = \"forward\")\n",
    "summary(regfit_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce026e9-ecae-43aa-a5b6-e14a22f58d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars <- summary(regfit_full)$which[which.min(summary(regfit_full)$bic), ]\n",
    "selected_vars <- names(selected_vars)[selected_vars == TRUE]\n",
    "selected_vars <- selected_vars[selected_vars != \"(Intercept)\"]  # remove intercept\n",
    "selected_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb153ef-8124-4473-b03e-a77b3bf30e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_data <- training_data %>% select(room_type, person_capacity, multi, biz, cleanliness_rating, bedrooms, dist, metro_dist, lng, lat, city, isWeekend, realSum)\n",
    "mlr_model <- lm(realSum ~ ., data = model_data)\n",
    "\n",
    "# View summary\n",
    "summary(mlr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd118d-e34f-44d0-816a-d28976939272",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_regsubsets <- testing_data %>% select(room_type, person_capacity, multi, biz, cleanliness_rating, bedrooms, dist, metro_dist, lng, lat, city, isWeekend, realSum)\n",
    "\n",
    "predictions_regsubsets <- predict(mlr_model, inputs_regsubsets)\n",
    "\n",
    "rmse_regsubsets <- rmse(actuals, predictions_regsubsets)\n",
    "rmse_regsubsets\n",
    "plot(actuals, predictions_regsubsets, main = \"Actual vs Predicted\", xlab = \"Actual\", ylab = \"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871326b-6f60-49f5-bc73-5724dbc3096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_regsubsets <- actuals - predictions_regsubsets\n",
    "plot(predictions_regsubsets, residuals_regsubsets,\n",
    "     main = \"Residuals vs Fitted (Predicted)\",\n",
    "     xlab = \"Fitted values\", ylab = \"Residuals\",\n",
    "     pch = 19, col = \"steelblue\")\n",
    "abline(h = 0, col = \"red\", lwd = 2)\n",
    "qqnorm(residuals_regsubsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1167a3-b2e6-45fa-a8d2-477543c2bff5",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "In this section, you’ll interpret the results you obtained in the previous section with respect to the main question/goal of your project.\n",
    "\n",
    "    Summarize what you found and the implications/impact of your findings.\n",
    "    If relevant, discuss whether your results were what you expected to find.\n",
    "    Discuss how your model could be improved;\n",
    "    Discuss future questions/research this study could lead to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c448f95-3e59-4bec-a8d3-31ec75e273c8",
   "metadata": {},
   "source": [
    "## 4) Methods and Plan (MARCUS)\n",
    "\n",
    "To answer my question, “*Is there an association between Airbnb prices to the distance to the closest metro and if the listing is for weekends?*“, I will use an additive MLR model using `lm()`, with the formula: `realSum ~ metro_dist + isWeekend`. This method is appropriate, because `lm()` allows us to quantify and test the significance of associations, with interpretable coefficients. Through hypothesis testing, we will either have evidence suggesting statistically significant associations (a p-value less than a chosen significance level for that coefficient), or not enough evidence.\n",
    "\n",
    "However, we need to make the following assumptions:\n",
    "- Linearity: There is a linear relationship between `realSum` and `metro_dist`.\n",
    "- Independence: The errors (observations) are independent of each other.\n",
    "- Normality: Under the CLT, since our data contains 23042 observations, the data and errors in the data are assumed to be normally distributed.\n",
    "- Homoscedasticity: The errors have constant variance.\n",
    "- There is no interaction between `metro_dist` and `isWeekend` on Airbnb prices. That is, the estimated change in Airbnb price for every change in distance to the metro does not differ depending on if the listing is on a weekend or not.\n",
    "- The covariates are not highly correlated (multicollinearity)\n",
    "\n",
    "There are also the following limitations:\n",
    "- Incorrect Assumptions: If some of our assumptions turn out to be false, then our results may be invalid or require corrections. For instance, if the relationship is non-linear, we may need to transform some covariates.\n",
    "- Confounding: Since the model only includes two variables, there may be other variables that influence both price and metro distance (ie. city). This could result in biased estimates, if not included in the model.\n",
    "- Outliers: Based on the EDA, the data is skewed with outliers, which may result in a model that does not capture representative patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d3275d-5ab7-422a-a761-ef143e6021e0",
   "metadata": {},
   "source": [
    "## (4) Methods and Plan (ALIZAH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8dcc34-80ea-454b-99ff-33738f136f27",
   "metadata": {},
   "source": [
    "We are planning on using multiple linear regression with interaction to estimate Airbnb prices based on city and distance from city centre. An MLR model is the appropriate choice for answering an inference question with 2 inputs and continuous numerical response. We will consider a model with interaction due to the results of the EDA: it seems the slope between `dist` and `realSum` are dependent on city. The formula for this regression will be: `realSum ~ city * dist`.<br>\n",
    "As with any model, there are certain assumption made about the data. The assumptions about MLR with interactionin relation to our data is as follows: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991b260-15c8-4058-9f91-fd6f6665e14d",
   "metadata": {},
   "source": [
    "- **Linearity:** Based on our EDA, we are assuming that our response is approximately a linear function of our inputs and their interaction term  \n",
    "- **Independence of Errors:** We assume that are observations are independent of each other. This data is from an outside source so we can never know this for sure.  \n",
    "- **Homoscedasticity:** We can test if the variance of errors is constant through a residuals vs fitted values plot.  \n",
    "- **Normality of Residuals:** We can see if the residuals have a normal distribution through a Q-Q plot.  \n",
    "- **Minimal Multicollinearity:** We can check if our inputs are highly correlated through their VIF score.  \n",
    "- **Correct Specification:** We are assuming that we have correctly specified the model with an interaction term from the result of our EDA. \n",
    "- **Correct Variable Encoding:** We ensured that, when we loaded the data, each relevant variable had the correct variable type for the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec70ee-ae42-4ead-9540-38add4150ac6",
   "metadata": {},
   "source": [
    "Following these assumptions ensures that the results from our model are appropriate for inference since we can attain reliable estimates, confidence intervals, and errors.\n",
    "There are still possible difficulties and weaknesses of our choice in model. Violating some of the assumptions may mean we cannot answer our question since it relies on making inferences. Adding in an interaction term could possible lead to overfitting the model, which may lead to poor predictions. Having too few input variables may mean that we result in a model with high errors if we are missing the potentially large impact of other variables. There's always the possiblity of confounding variables as well. Since this is an external observational study, we cannot easily discover or isolate them from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa7e08-5792-4f29-a06f-e6f07e31236e",
   "metadata": {},
   "source": [
    "To summarize, we can use a MLR model with interaction to infer the association between the listing price of all Airbnbs in Rome, Budapest, and London depending on their city and distance from city centre. Our EDA justifies the appropriateness of this model. However, there are assumptions for this type of model we'd have to further test for and other possible weaknesses that may prevent us from answering our inference question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd15bf2-76ef-4701-8c7f-330f65f64ad4",
   "metadata": {},
   "source": [
    "<h3><b>4.Methods and Plan (ZAHRA) <b></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221a7f9-7807-4abd-a919-43b889a2462f",
   "metadata": {},
   "source": [
    "<p>\n",
    "    To address the question of how <strong>Airbnb price (<code>realSum</code>)</strong> is associated with \n",
    "    <strong>distance from the city center (<code>dist</code>)</strong> and \n",
    "    <strong>business use (<code>biz</code>)</strong>, \n",
    "    I propose using a <strong>multiple linear regression model with an interaction term</strong>:\n",
    "  </p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2494f-0c9f-449f-bf83-681e98255700",
   "metadata": {},
   "source": [
    "<blockquote><code>realSum ~ biz * dist</code></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75584997-7fd3-4f8b-830c-d4f84956f8e5",
   "metadata": {},
   "source": [
    "<p>\n",
    "    This model includes both the main effects and their interaction, enabling us to determine whether \n",
    "    the relationship between price and distance varies by business use status.\n",
    "  </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbcdfea-1042-4996-bf41-7a92f0a3f807",
   "metadata": {},
   "source": [
    "<h3>Why is this method appropriate?</h3>\n",
    "  <ul>\n",
    "    <li>Multiple linear regression models are suitable for analyzing the effect of several predictors on a continuous outcome.</li>\n",
    "    <li>There is an interaction between  <b>biz</b> and <b>dist</b> as shown by the scatterplot above </li>\n",
    "    <li>The method is interpretable and statistically efficient when assumptions are met.</li>\n",
    "  </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee43f6-813f-4e37-9e05-cfff76ef4bf0",
   "metadata": {},
   "source": [
    "<h3>Assumptions of the Method</h3>\n",
    "  <ul>\n",
    "    <li><strong>Linearity:</strong> A linear relationship exists between predictors and the outcome.</li>\n",
    "    <li><strong>Independence:</strong> Observations are independent.</li>\n",
    "    <li><strong>Homoscedasticity:</strong> Constant variance of residuals across predictor values.</li>\n",
    "    <li><strong>Normality of residuals:</strong> Residuals should follow a normal distribution.</li>\n",
    "    <li><strong>No multicollinearity:</strong> Predictors should not be highly correlated.</li>\n",
    "  </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91983783-ac08-47ce-a1f3-f209efc7219a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    " <h3>Potential Limitations or Weaknesses</h3>\n",
    "  <ul>\n",
    "    <li>Price data may be skewed or contain outliers that violate regression assumptions.</li>\n",
    "    <li>The relationship may not be strictly linear, limiting model fit.</li>\n",
    "    <li>Interpreting interaction terms can be complex.</li>\n",
    "    <li>Unmeasured variables (e.g., amenities, neighborhood) might bias results.</li>\n",
    "  </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753bec6-2922-4b35-8844-4d7042dae914",
   "metadata": {},
   "source": [
    "## Methods and plans (MATTHEW)\n",
    "\n",
    "To answer the question, I believe the best method to approach it would be the Multi-Linear Regression (MLR) model. This is because the MLR model would allow me to observe and predict the change in the price of the listings with every unit increase in distance from city centre or between different room capacities in each city. Two assumptions that will be made for this model is that the change in the price of the listings with the change of room capacities is the same across all cities, and the other assumption is that the change in price of listings with every kilometer increase of distance from the city centre is different between cities. There are limitations of this method, such that if the response and inputs aren't linearly related, it may lead to a model with poor fit. It also assumes that the variation of residuals are homoschedastic, it will affect the standard error of our estimators and invalidate our confidence intervals and p-values if they are heterschedastic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529829a-9259-4cdf-acbd-08bc809332a6",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "At least two citations of literature relevant to the project. The citation format is your choice – just be consistent. Make sure to cite the source of your data as well.\n",
    "\n",
    "https://www.tandfonline.com/doi/full/10.1080/1331677X.2021.1962380#abstract \n",
    "https://www.sciencedirect.com/science/article/pii/S0261517721000388?via%3Dihub "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ed11b-ff7c-4002-8ef4-7e36f5ebb693",
   "metadata": {},
   "source": [
    "Testing push - Alizah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bf9d6-1be9-4e28-bde5-0be838bc654b",
   "metadata": {},
   "source": [
    "Testing push - Matthew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc0583d-a311-47ef-b211-d2165b1e6528",
   "metadata": {},
   "source": [
    "testing push - Zahra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63121e8-8982-4614-9d8e-b951550e92a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
