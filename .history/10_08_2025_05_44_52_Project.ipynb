{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be06998-d3c5-4fa8-985c-07249e7c6c78",
   "metadata": {},
   "source": [
    "# Predicting Airbnb Price in European Cities "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aba0b8-6b3d-4b36-9a60-dd395034c59c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "**Group 15** <br>\n",
    "Mathew <br>\n",
    "Marcus <br>\n",
    "Zahra <br>\n",
    "Alizah <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e20d37-9d20-4929-a2f0-77d7019f3bd7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Airbnb has revolutionized the short-term rental market, making tourism and travel more accessible and convenient. As a popular alternative to traditional hotels, hosts can monetize their properties by listing it on the platform, enabling guests to customize and enrich their travel experiences. In Europe, tourism plays a significant role in many cities’ economies, and understanding the factors that influence listing prices will help explain what truly adds value to a stay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64131c11-f0af-4922-8547-5ccf0ec270dd",
   "metadata": {},
   "source": [
    "#### Literature Review\n",
    "\n",
    "Listing reputation was associated with a negative effect on price, as hosts with lower prices may attract more guests and reviews ([Toader, Victor, et al, 2021](https://doi.org/10.1080/1331677x.2021.1962380)). The same study also associated the number of bedrooms and guest capacity with the largest price changes. \n",
    "\n",
    "Listing prices have also been concluded to be spatially dependent, changing with distance from city centre, distance to the nearest metro station, and distances to major attractions ([Gyódi, Karol, and Łukasz Nawaro, 2021](https://doi.org/10.1016/j.tourman.2021.104319)). The authors determined that Airbnb prices decrease further from city centre and metro stations, but increase in the vicinity of popular tourist attractions and restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b9719-da90-413a-82af-e072eb7fc289",
   "metadata": {},
   "source": [
    "#### **Our Question:** Which factors are most useful for predicting the price of an Airbnb listing?\n",
    "\n",
    "Confirming the importance of location and other factors, and being able to estimate listing prices with good accuracy, is helpful for both hosts and guests. Beyond tourism management, understanding Airbnb prices will also be informative for urban planning, expanding upon previous studies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba84f9-56f8-45b0-bf5b-7cb9d7d99d55",
   "metadata": {},
   "source": [
    "## Data Description:\n",
    "Our analysis will use the dataset [Airbnb Prices in European Cities](https://www.kaggle.com/datasets/thedevastator/airbnb-prices-in-european-cities/data).\n",
    "\n",
    "The data appears to be aggregated from Airbnb listings from several major European cities. The cities we will focus on are London, Rome, and Budapest, on weekends and weekdays, for a total of `23042` observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576006f2-b25b-496c-99d1-e6e3f3ea1e97",
   "metadata": {},
   "source": [
    "There are 20 variables in the original dataset, but we drop `id`, `attr_index`, `attr_index_norm`, `rest_index`, and `rest_index_norm` as they aren’t explained in detail. This leaves us with 15 variables:\n",
    "\n",
    "| Column name   | Description   | Data Type     |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| `realSum` | The total price of the Airbnb listing (Euros). | Numeric |\n",
    "| `room_type` | The type of room being offered (e.g. private, shared, etc.). | Categorical |\n",
    "| `room_shared` | Whether the room is shared or not. | Boolean |\n",
    "| `room_private` | Whether the room is private or not. | Boolean |\n",
    "| `person_capacity` | The maximum number of people that can stay in the room. | Numeric |\n",
    "| `host_is_superhost` | Whether the host is a superhost or not. | Boolean |\n",
    "| `multi` | Whether the listing is for multiple rooms or not. | Boolean |\n",
    "| `biz` | Whether the listing is for business purposes or not. | Boolean |\n",
    "| `cleanliness_rating` | The cleanliness rating of the listing. | Numeric |\n",
    "| `guest_satisfaction_overall` | The overall guest satisfaction rating of the listing. | Numeric |\n",
    "| `bedrooms` | The number of bedrooms in the listing. | Numeric |\n",
    "| `dist` | The distance from the city centre. | Numeric |\n",
    "| `metro_dist` | The distance from the nearest metro station. | Numeric |\n",
    "| `lng` | The longitude of the listing. | Numeric |\n",
    "| `lat` | The latitude of the listing. | Numeric |\n",
    "\n",
    "\n",
    "The following two variables will be added to the data when imported: \n",
    "\n",
    "| Column name   | Description   | Data Type     |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| `city` | The city location of the Airbnb listing. | Categorical |\n",
    "| `isWeekend` | Whether the listing is for weekends or not. | Boolean |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53dbc17-e7e0-4d4a-a1a6-db0fb661c434",
   "metadata": {},
   "source": [
    "# Methods and Results\n",
    "## a) Exploratory Data Analysis\n",
    "We start by reading our data and drop the columns we do not need (`id`, `attr_index`, `attr_index_norm`, `rest_index` and `rest_index_norm`). We will also drop `lng` and `lat`, because they must be considered in a combined and discrete manner to be meaningful. We will also correct the following columns:\n",
    "\n",
    "- `room_type` from \\<chr\\> to factor (\\<fct\\>) \n",
    "- `multi` & `biz` from \\<dbl\\> to logicals (\\<lgl\\>) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127db2dc-ef75-4d5c-9d2b-ca9f757bcf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"mltools\")\n",
    "install.packages(\"glmnet\")\n",
    "install.packages(\"leaps\")\n",
    "# You may need to run these functions if certain packages are not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30993725-dabf-4660-9c9d-dce36c90c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries & Packages\n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(mltools)\n",
    "library(rsample)\n",
    "library(MASS)\n",
    "library(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581ad4a-fb75-4e60-b36c-82e1c0d5512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "# Contributor: Marcus (modified read function)\n",
    "\n",
    "# Function to format & read data: \n",
    "# select vars from dataset and add city name + if it's weekend data\n",
    "tidy_data <- function(path, cityName, isWeekend) {\n",
    "    data <- read_csv(path, show_col_types = FALSE) %>%\n",
    "            dplyr::select(-...1, -attr_index, -attr_index_norm, -rest_index, \n",
    "                          -rest_index_norm, -lng, -lat) # Drop columns\n",
    "    data$city <- as.factor(cityName)        # The city location of the Airbnb listing (Categorical)\n",
    "    data$isWeekend <- as.logical(isWeekend) # Whether the listing is for weekends or not. (Boolean)\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "# Import and format data with tidy_data()\n",
    "london_weekdays <- tidy_data(\"data/london_weekdays.csv\", \"London\", 0)\n",
    "london_weekends <- tidy_data(\"data/london_weekends.csv\", \"London\", 1)\n",
    "rome_weekdays <- tidy_data(\"data/rome_weekdays.csv\", \"Rome\", 0)\n",
    "rome_weekends <- tidy_data(\"data/rome_weekends.csv\", \"Rome\", 1)\n",
    "budapest_weekdays <- tidy_data(\"data/budapest_weekdays.csv\", \"Budapest\", 0)\n",
    "budapest_weekends <- tidy_data(\"data/budapest_weekends.csv\", \"Budapest\", 1)\n",
    "\n",
    "# Merge all the data together\n",
    "data <- rbind(london_weekdays, london_weekends, rome_weekdays, rome_weekends, budapest_weekdays, budapest_weekends)\n",
    "\n",
    "# View the head and tail of the data\n",
    "head(data, 3)\n",
    "tail(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecbfd1-f18b-46d1-bff5-e7b788e6442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Matthew\n",
    "# Contributor: Zahra (Style Guide)\n",
    "\n",
    "# Correct the columns with wrong type\n",
    "data <- data %>%\n",
    "    mutate(\n",
    "        #Convert to factor\n",
    "        across(c(room_type), as.factor),\n",
    "        \n",
    "        #Convert to logical\n",
    "        across(c(multi, biz), as.logical)\n",
    "    )\n",
    "\n",
    "# View the corrected head of the data\n",
    "head(data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add969a-5534-44bb-94a6-ac4af131821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "# Contributor: Alizah (organized output)\n",
    "\n",
    "# Inspect data structure\n",
    "str(data)\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Check for missing/NA values\n",
    "cat(\"NA values present?: \", anyNA(data))\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Compute summary statistics & check numbers\n",
    "cat(\"Data dimensions: \", dim(data))\n",
    "cat(\"\\n\\n\")\n",
    "cat(\"Summary of realSum\")\n",
    "summary(data$realSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e893a-b474-42ef-8e9b-a5968b113f9f",
   "metadata": {},
   "source": [
    "Above, we see `realSum` with a maximum value of `15499.89`, minimum of `34.78`, and a mean of `268.47`. This suggests the presence of outliers. Let’s visualize the distribution of `realSum` with a histogram to further examine outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46ac28-88ee-4618-ad5a-6d04790d1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "# Contributor: Zahra (Style Guide)\n",
    "\n",
    "# Adjust size of plots\n",
    "options(repr.plot.width = 8, repr.plot.height = 5)\n",
    "\n",
    "# Plot a histogram of our response variable realSum\n",
    "realSum_hist <- data %>%\n",
    "    ggplot(aes(x = realSum)) +\n",
    "    geom_histogram(fill = \"gray\", color = \"black\") +\n",
    "    labs(\n",
    "        title = \"Histogram of Airbnb Prices\", \n",
    "        x = \"Total Airbnb Price (Euros)\", \n",
    "        y = \"Count\"\n",
    "    ) +\n",
    "    theme(\n",
    "        axis.text = element_text(size = 16), \n",
    "        axis.title = element_text(size = 16),\n",
    "        title = element_text(size = 20)\n",
    "    )\n",
    "\n",
    "realSum_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3f60b-6c09-40ed-93c9-4881efb0846c",
   "metadata": {},
   "source": [
    "Above, we see high outliers in `realSum`. Let’s filter them by removing the 95th percentile, grouped by cities, and plot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebede97-8467-4665-a211-ef8993ceb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Matthew\n",
    "# Contributor: Zahra (Style Guide)\n",
    "\n",
    "# Filtering Outliers from each city by removing listings above the 95th percentile\n",
    "data_filt <- data %>% \n",
    "    group_by(city) %>%\n",
    "    filter(realSum <= quantile(realSum, 0.95, na.rm = TRUE)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb94d59-809d-4e05-8886-b5d4c77ab5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "# Contributor: Zahra (Style Guide and Aesthetics)\n",
    "\n",
    "# Plot filtered histogram with Mean and 95th Percentile lines\n",
    "realSum_hist_filt <- data_filt %>%\n",
    "    ggplot(aes(x = realSum)) +\n",
    "    geom_histogram(fill = \"gray\", color = \"black\") +\n",
    "    geom_vline(xintercept = mean(data$realSum), color = \"red\", linetype = \"dashed\", size = 1) +\n",
    "    geom_vline(xintercept = quantile(data$realSum, 0.95), color = \"blue\", linetype = \"dashed\", size = 1) +\n",
    "    scale_x_continuous(breaks = seq(0, 1000, 100)) +\n",
    "    ggtitle(\"Histogram of Airbnb Prices at 95th percentile\\nwith 95% threshold (blue) and mean price (red)\") +\n",
    "    labs(x = \"Total Airbnb Price\", y = \"Count\") +\n",
    "    theme(\n",
    "        axis.text = element_text(size = 15), \n",
    "        axis.title = element_text(size = 15),\n",
    "        title = element_text(size = 16)\n",
    "    )\n",
    "    \n",
    "realSum_hist_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db38c7-678c-42d5-9e18-e0f42b6e7704",
   "metadata": {},
   "source": [
    "Our filtered data appears right-skewed. 95% of Airbnb price listings fall below about `900` grouped by city, but fall below about `640` for the entire dataset, so we need to explore `city`. There’s also low outliers under `100`, so we’ll drop them by filtering listings below the 5th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff4f46-84c5-441d-973c-4e86629011e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Matthew\n",
    "\n",
    "# Filter again to exclude lower 5%\n",
    "data_filt <- data_filt %>%\n",
    "    group_by(city) %>%\n",
    "    filter(realSum >= quantile(realSum, 0.05, na.rm = TRUE)) %>%\n",
    "    ungroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653326-d5a2-4763-95f6-ff3b4a4414ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Matthew\n",
    "# Contributor: Zahra (Style Guide)\n",
    "\n",
    "#Set plot size\n",
    "options(repr.plot.height = 6, repr.plot.width = 8)\n",
    "\n",
    "# Creating a Boxplot to examine distribution of listing prices by city\n",
    "city_listing_plot <-\n",
    "    data_filt %>%\n",
    "    ggplot(aes(x = city, y = realSum, fill = city)) +\n",
    "    geom_boxplot()+\n",
    "    stat_summary(\n",
    "        aes(x = city, y = realSum),\n",
    "        fun = mean, \n",
    "        geom = \"point\", \n",
    "        colour = \"yellow\", \n",
    "        shape = 18, \n",
    "        size = 5\n",
    "    ) +\n",
    "    ggtitle(\"Distribution of Listing Prices in Different Cities\") +\n",
    "    xlab(\"Cities\") +\n",
    "    ylab(\"Listing Prices (EUR)\") +\n",
    "    theme(\n",
    "        text = element_text(size = 12),\n",
    "        plot.title = element_text(face = \"bold\"),\n",
    "        axis.title = element_text(face = \"bold\")\n",
    "    )\n",
    "city_listing_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8454310-7010-42e4-b9aa-c0e132a303c7",
   "metadata": {},
   "source": [
    "The box plot above shows the distribution of listing prices across London, Rome and Budapest. \n",
    "\n",
    "- Budapest (Blue) appears to have the smallest variability as well as the lowest median and mean.\n",
    "- London (Red) has the largest variability and the highest median and mean.\n",
    "- Lastly, Rome (Green) has a variability, median and mean higher than Budapest but lower than London.\n",
    "- Budapest and Rome share a relatively similar spread, median and mean of listing prices to one another. However, London's wider distribution and higher median and mean may affect the goodness of fit of the model.\n",
    "\n",
    "Lastly, let's plot a correlation matrix to explore all associations between inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092a78b-c1da-4142-9fd9-8f5a1db2025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Marcus (Referenced from STAT 301 Tutorial 3)\n",
    "\n",
    "# Select only numeric & drop response, then get melted correlation matrix\n",
    "corr_matrix <- \n",
    "    data_filt %>%\n",
    "    dplyr::select(where(is.numeric)) %>%\n",
    "    dplyr::select(-realSum) %>%\n",
    "    cor() %>%\n",
    "    as_tibble(rownames = 'var1') %>%\n",
    "    pivot_longer(-var1, names_to = \"var2\", values_to = \"corr\")\n",
    "\n",
    "head(corr_matrix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bd8d9-c769-43ee-9f86-0c9133c31349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Marcus (Referenced from STAT 301 Tutorial 3)\n",
    "\n",
    "options(repr.plot.width = 12, repr.plot.height = 8) \n",
    "# You may need this to generate the plot\n",
    "options(jupyter.plot_mimetypes = \"image/png\")\n",
    "\n",
    "plot_corr_matrix <- corr_matrix %>%\n",
    "    ggplot(aes(var1, var2)) +\n",
    "    geom_tile(aes(fill = corr), color = \"white\") +\n",
    "    scale_fill_distiller(\"Correlation Coefficient \\n\",\n",
    "        palette =  \"YlOrRd\",\n",
    "        direction = 1, \n",
    "        limits = c(-1.0, 1.0)\n",
    "    ) +\n",
    "    labs(x = \"Input Variable 1\", y = \"Input Variable 2\") +\n",
    "    theme_minimal() +\n",
    "    theme(\n",
    "        axis.text.x = element_text(angle = 45, vjust = 1, size = 14, hjust = 1),\n",
    "        axis.text.y = element_text(vjust = 1, size = 14, hjust = 1),\n",
    "        legend.title = element_text(size = 18),\n",
    "        legend.text = element_text(size = 12),\n",
    "        legend.key.size = unit(1.5, \"cm\")\n",
    "    ) +\n",
    "    coord_fixed() +\n",
    "    geom_text(aes(var1, var2, label = round(corr, 2)), color = \"black\", size = 6)\n",
    "\n",
    "plot_corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb969e-1858-4ea3-9a23-b8cf620d40c3",
   "metadata": {},
   "source": [
    "Above, there seem to be moderate (< 0.75) correlations between `person_capacity` and `bedrooms`, `metro_dist` and `dist`, and `guest_satisfaction_overall` and `cleanliness_rating`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed76d4-f706-446a-a147-addffc8dfe4d",
   "metadata": {},
   "source": [
    "## b) Analysis \n",
    "\n",
    "Our question involves both inference and prediction. We separated the data into testing and training sets to prevent post-inference problems and to get an unbiased understanding of our model's scalability and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcdf62-b4a0-438c-984b-c985a17845b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Splitting & Initial Fit\n",
    "\n",
    "We used `initial_split` (from `rsample`) to randomly split our dataset, stratified by `realSum` with 80/20 training-test split. For the rest of the analysis, we ensured the testing data was not leaked into the model.\n",
    "\n",
    "First, we fit a baseline (intercept-only) model as a point of comparison. Our main model used `stepAIC` to systematically select the most important factors for predicting our listing price. \n",
    "\n",
    "We chose `stepAIC` with forward selection, because `stepAIC` takes multicollinearity into account unlike LASSO regularization, which may randomly drop predictors with similar model contributions. It also considers categorical variables as a whole rather than by each dummy variable created, in contrast to `regsubsets`.\n",
    "\n",
    "`stepAIC` with forward selection adds predictors one by one to the baseline model, choosing the predictor that yields the largest drop in AIC (a metric used to compare model fit). This process repeats until no further AIC improvement is possible, balancing overfitting and underfitting to find the least complex model with the best fit. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f5cdc-5eb4-49e3-ad23-e97fb041ad8f",
   "metadata": {},
   "source": [
    "### Checking Assumptions:\n",
    "We assumed independence of observations. For additive models, we assumed no combined interactions (between predictors) that influence the response.\n",
    "\n",
    "We check our model assumptions for linearity, normality, homoscedasticity and collinearity. Although we have enough observations (23042) to apply the CLT and assume normality, it is good to check.\n",
    "\n",
    "Residuals vs. Fitted Plot (Figure 1):\n",
    "- To check linearity, the plot should have the same number of points above/below the reference line at any value of fitted values. \n",
    "- To check homoscedasticity, the plot should not look like a “cone”.\n",
    "\n",
    "Q-Q Plot (Figure 2): \n",
    "- To check normality, the plot should show points that align with the reference line.\n",
    "\n",
    "To check for multicollinearity, we used `vif` to find highly collinear variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e56e9-064b-4f1d-9884-18cd0badaace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing & Evaluation:\n",
    "To validate assumptions, we log-transformed `realSum` and dropped collinear variables `room_shared` and `room_private`. We also standardized the numerical predictors.\n",
    "\n",
    "Then, we used the transformed data with `stepAIC` and validated assumptions (Figure 3 & 4). We extracted selected predictors and fit them on an `lm` model.\n",
    "\n",
    "We called `predict` with our finalized model and testing dataset and calculated the Root-Mean Squared Error using `rmse` (from `mltools`). RMSE is more sensitive to large errors because it squares them, helping us measure price prediction accuracy to a finer extent (every euro counts). Lower RMSE suggests better model accuracy. We also plotted our predicted and actual values as a visual aid of our model's performance (Figure 5). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8032a7-ea33-44fc-b248-526b6834d80f",
   "metadata": {},
   "source": [
    "## c) Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfd70d-1121-4806-809f-2535ef30267e",
   "metadata": {},
   "source": [
    "### Splitting + Initial Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25309788-1e37-44ef-9874-1bbff63e01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "\n",
    "set.seed(1515)\n",
    "\n",
    "# Split data between Training and Testing data, not standardized\n",
    "data_split <- initial_split(data_filt, prop = 0.8, strata = realSum)\n",
    "training_data <- training(data_split)\n",
    "testing_data <- testing(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acc715-0f5b-40e7-b8b2-f7300b9d8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "\n",
    "# Use the Intercept-Only Model as a Baseline for performance\n",
    "baseline_model <- lm(realSum ~ 1, data = training_data)\n",
    "\n",
    "# Run forward selection starting from baseline model (full_model is the upper boundary)\n",
    "full_model <- lm(realSum ~ ., data = training_data)\n",
    "\n",
    "step_model <- stepAIC(\n",
    "    baseline_model, \n",
    "    scope = list(lower = baseline_model, upper = full_model),\n",
    "    direction = \"forward\",\n",
    "    trace = FALSE) # minimizes output\n",
    "\n",
    "# THIS CELL MAY TAKE A WHILE TO RUN\n",
    "# RESULTS SHOWN IN NEXT CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d240d-6733-4c5f-8301-0f97410ae5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "\n",
    "# Viewing the selected predictors\n",
    "final_formula = formula(step_model)\n",
    "final_formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056cd89-0b65-4364-b77e-52dbc32288e1",
   "metadata": {},
   "source": [
    "### Checking Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b52645-62ff-4514-b5cf-9ee12cd17eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "# Collaborator: Zahra (Histogram of Residuals)\n",
    "\n",
    "# Get Residuals\n",
    "residuals <- resid(step_model)\n",
    "fitted_vals <- fitted(step_model)\n",
    "\n",
    "# 1. Residuals vs Fitted plot (for linearity & homoscedasticity)\n",
    "plot(fitted_vals, residuals, xlab = \"Fitted values\", ylab = \"Residuals\")\n",
    "abline(h = 0, col = \"red\")\n",
    "title(\"Figure 1: Residuals vs Fitted\")\n",
    "\n",
    "# 2. QQ plot (for normality)\n",
    "qqnorm(residuals, main = \"Figure 2: Normal Q-Q Plot\")\n",
    "qqline(residuals, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01241ddd-ce7d-4504-90f2-cf263c9d4c54",
   "metadata": {},
   "source": [
    "Examining the plots:\n",
    "\n",
    "- **Figure 1: Residuals vs Fitted Plot:** The plot shows a different number of points above and below the reference line and has somewhat of a “cone” shape, suggesting a violation of the linearity and homoscedasticity assumptions. \n",
    "\n",
    "- **Figure 2: Q-Q Plot:** The points near the ends of the reference line deviate from the line significantly, suggesting a violation of normality.\n",
    "\n",
    "Log-transforming the response `realSum` should validate these assumptions. Below, we check for multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798da2c-5d80-49ee-b8dc-517a3ca276bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Alizah\n",
    "\n",
    "# Find the aliases in the linear model \n",
    "# vif() will result in an error if there is perfect multicollinearity anywhere so we have to remove that first\n",
    "alias_structure <- alias(lm(realSum ~ ., data = data_filt))\n",
    "alias_vars <- rownames(alias_structure$Complete)\n",
    "cat(\"Variables to Remove: \", alias_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b950e3f-5df6-43bb-8e44-403eca273537",
   "metadata": {},
   "source": [
    "We must remove 'room_shared' and 'room_private' in order to run `vif`, as they have perfect multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710700f-1ac2-4925-981d-de8492acec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Alizah\n",
    "\n",
    "data_noalias <- dplyr::select(data_filt, -room_shared, -room_private)\n",
    "full_model_noalias <- lm(realSum ~ ., data = data_noalias)\n",
    "\n",
    "cat(\"Table 1: vif output\")\n",
    "vif(full_model_noalias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820adcb-4470-426c-8836-aca02e80df46",
   "metadata": {},
   "source": [
    "The values under the last column are all $< \\sqrt{5} \\approx 2.24$, verifying minimal multicollinearity between the remaining predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc4e25-f1a0-4c97-9db9-513f7d38b89a",
   "metadata": {},
   "source": [
    "### Testing & Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08e4d1-2dd6-4cb3-84f7-ebb830755204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Marcus\n",
    "\n",
    "# Standardize the data by log-transforming realSum and scaling numerical variables\n",
    "training_data_std <- training_data %>%\n",
    "    mutate(realSum = log(realSum)) %>%  # Log-transform realSum\n",
    "    mutate(across(\n",
    "      .cols = where(is.numeric) & !any_of(\"realSum\"),  # All numeric vars except realSum\n",
    "      .fns = ~ scale(.)\n",
    "    )) %>%\n",
    "    dplyr::select(-room_shared, -room_private) # Drop collinear variables\n",
    "\n",
    "# We do not peek at the testing data or leak any into our model\n",
    "testing_data_std <- testing_data %>%\n",
    "    mutate(realSum = log(realSum)) %>%  # Log-transform realSum\n",
    "    mutate(across(\n",
    "      .cols = where(is.numeric) & !any_of(\"realSum\"),  # All numeric vars except realSum\n",
    "      .fns = ~ scale(.)\n",
    "    )) %>%\n",
    "    dplyr::select(-room_shared, -room_private) # Drop collinear variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1f260-f1ec-4894-8231-7d097c055e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "\n",
    "# Use the Intercept-Only Model, Standardized, as a Baseline for performance\n",
    "baseline_model_std <- lm(realSum ~ 1, data = training_data_std)\n",
    "\n",
    "# Calculate RMSE using baseline model on testing data\n",
    "predictions <- predict(baseline_model_std, testing_data_std)\n",
    "\n",
    "rmse_baseline <- rmse(testing_data_std$realSum, predictions)\n",
    "cat(\"RMSE Baseline (Scaled): \", rmse_baseline)\n",
    "\n",
    "actuals_original <- exp(testing_data_std$realSum)\n",
    "predictions_original <- exp(predictions)\n",
    "rmse_baseline_original <- rmse(actuals_original, predictions_original)\n",
    "cat(\"\\n\")\n",
    "cat(\"RMSE Baseline (Original, in Euros): \", rmse_baseline_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff1946-451a-4d7e-be68-727a52c08dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Alizah\n",
    "\n",
    "# Run forward selection starting from baseline model (full_model is the upper boundary)\n",
    "full_model_std <- lm(realSum ~ ., data = training_data_std)\n",
    "\n",
    "step_model_std <- stepAIC(\n",
    "    baseline_model_std, \n",
    "    scope = list(lower = baseline_model_std, upper = full_model_std),\n",
    "    direction = \"forward\",\n",
    "    trace = FALSE) # minimizes output\n",
    "\n",
    "# THIS CELL MAY TAKE A WHILE TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fb4ce-4617-4fd0-ad5d-b29f9a07ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the selected predictors\n",
    "final_formula_std = formula(step_model_std)\n",
    "final_formula_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4235f-4033-4dad-af02-50131c1aa050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Alizah\n",
    "# Contributor: Zahra(Style Guide)\n",
    "\n",
    "# Create Final Prediction Model Using Selected Predictors\n",
    "final_model = lm(final_formula_std, data = training_data_std)\n",
    "summary(final_model) # Generate important summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89705be-b36a-4b97-83fd-b4ac9e14c1ba",
   "metadata": {},
   "source": [
    "Above, the least significant predictors are `metro_dist` and `guest_satisfaction_overall`, which remained in the model as `stepAIC` uses AIC rather than p-values to balance fit and complexity. For our inferential purposes, these will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3edd142-b251-4671-9760-cb857b526c52",
   "metadata": {},
   "source": [
    "### Validating Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e13ca-9bae-49b7-a0e1-f7d9c5bc3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "# Collaborator: Zahra (Histogram of Residuals)\n",
    "\n",
    "# Get Residuals\n",
    "residuals <- resid(step_model_std)\n",
    "fitted_vals <- fitted(step_model_std)\n",
    "\n",
    "# 1. Residuals vs Fitted plot (for linearity & homoscedasticity)\n",
    "plot(fitted_vals, residuals, xlab = \"Fitted values\", ylab = \"Residuals\")\n",
    "abline(h = 0, col = \"red\")\n",
    "title(\"Figure 3: Residuals vs Fitted for Standardized data\")\n",
    "\n",
    "# 2. QQ plot (for normality)\n",
    "qqnorm(residuals, main = \"Figure 4: Normal Q-Q Plot for Standardized data\")\n",
    "qqline(residuals, col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3ee09-8ab4-4f5f-8071-8dc72928ae95",
   "metadata": {},
   "source": [
    "- **Figure 3: Residuals vs Fitted Plot, Standardized:** The points above and below the line appear equally distributed in an elliptical distribution, validating the assumption of linearity and homoscedasticity (constant variance). \n",
    "- **Figure 4: Q-Q Plot, Standardized:** The points fit better with the reference line, validating the assumption of normality. However, it remains slightly curved upwards at both ends.\n",
    "\n",
    "Now, let’s evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7e811-f653-4d91-aee2-3faab5ba8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main developer: Alizah\n",
    "\n",
    "# Predicting listing prices (realSum) with our model \n",
    "predictions <- predict(final_model, testing_data_std)\n",
    "actuals <- testing_data_std$realSum\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse_model <- rmse(testing_data_std$realSum, predictions)\n",
    "\n",
    "actuals_original <- exp(actuals)\n",
    "predictions_original <- exp(predictions)\n",
    "rmse_model_original <- rmse(actuals_original, predictions_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d102cf-6841-4a10-a500-8b78138302b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Alizah\n",
    "# Collaborator: Zahra\n",
    "\n",
    "# Compile metrics into a table\n",
    "metrics <- data.frame(\n",
    "    metric = c(\"Baseline RMSE\", \"Model RMSE\"),\n",
    "    log_value = c(rmse_baseline, rmse_model),\n",
    "    value = c(rmse_baseline_original, rmse_model_original)\n",
    ")\n",
    "\n",
    "cat(\"Table 1: Result Metrics\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3b2b7-3fc3-4014-9f55-069128fe8b8b",
   "metadata": {},
   "source": [
    "We can see that the model we created using stepAIC() has a much better RMSE value than our baseline model, which indicates that using our selected variables lead to a more accurate prediction of realSum values as compared to simply using the mean response value. \n",
    "\n",
    "As an added visual for our model performance, we plot model predictions against the observed values from our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9b3cb-c869-4b15-903c-df363fb67253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Developer: Zahra \n",
    "\n",
    "# Plotting Model Predictions vs. Actuals\n",
    "# Create plot data\n",
    "plot_data <- data.frame(actuals = testing_data_std$realSum,\n",
    "                        predictions = predict(final_model, testing_data_std))\n",
    "\n",
    "# Extract the baseline model intercept\n",
    "baseline_intercept <- coef(baseline_model_std)[1]\n",
    "\n",
    "# Build plot\n",
    "ggplot(plot_data, aes(x = actuals, y = predictions)) +\n",
    "  geom_point(aes(color = \"Predicted Values\")) +\n",
    "  \n",
    "  # Ideal y = x line\n",
    "  geom_abline(aes(color = \"Ideal Fit\"), slope = 1, intercept = 0, linetype = \"dashed\", linewidth = 1) +\n",
    "  \n",
    "  # Fitted trend line\n",
    "  geom_smooth(aes(color = \"Model Trend\"), method = \"lm\", se = FALSE, linewidth = 1) +\n",
    "  \n",
    "  # Horizontal line for baseline model intercept\n",
    "  geom_hline(aes(yintercept = baseline_intercept, color = \"Baseline Model\"),\n",
    "             linetype = \"dotdash\", linewidth = 1) +\n",
    "  \n",
    "  # Manual color and legend mapping\n",
    "  scale_color_manual(\n",
    "    name = \"Legend\",\n",
    "    values = c(\n",
    "      \"Predicted Values\" = \"lightblue\",\n",
    "      \"Ideal Fit\" = \"red\",\n",
    "      \"Model Trend\" = \"blue\",\n",
    "      \"Baseline Model\" = \"darkgreen\"\n",
    "    )\n",
    "  ) +\n",
    "  \n",
    "  labs(\n",
    "    title = \"Figure 7: \\nActual vs Predicted Prices with Model Trends\",\n",
    "    x = \"Actual Log Price\",\n",
    "    y = \"Predicted Log Price\"\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"bottom\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fdfcfe-a4dd-4c7a-ac6d-526f7a706a98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ideally, if our model has complete accuracy, its trendline would be y=x, which is shown as a dashed diagonal line. In Figure 5, We can see that our model trend line isn’t similar. For actual values lower than mean(realSum), our predictions are a bit higher. For actual values higher than mean(realSum), our predictions are a bit lower.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1167a3-b2e6-45fa-a8d2-477543c2bff5",
   "metadata": {},
   "source": [
    "# 3) Discussion\n",
    "\n",
    "Through stepwise variable selection using `stepAIC`, we obtained the formula above. This formula contains 11 of the 15 analysis variables we started with.\n",
    "\n",
    "We expected to find location, listing size, quality and host reputation to be important factors. From above, we confirm location, specifically distance to the city center (`city`) to be negatively associated with price. We also confirm listing size (`person_capacity`, `bedrooms`, `multi`) and quality (`cleanliness_rating`) to be positively associated with price. However, it appears that host reputation (`host_is_superhost`) was not included in the model as a strong predictor. Moreover, we note the following:\n",
    "\n",
    "- Rome and Budapest are negatively associated with price. This matches our EDA.\n",
    "- Private and Shared rooms are negatively associated with price. We would expect Private rooms to be positively associated, but they are not.\n",
    "- Listings for business use are positively associated with price.\n",
    "- Listings for weekends are positively associated with price.\n",
    "\n",
    "Our model had an RMSE $\\approx$ `0.29` ($\\approx$ 141 $\\texteuro$), compared to the baseline with RMSE $\\approx$ `0.48` ($\\approx$ 83 $\\texteuro$). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27655e-8563-4159-a9d5-d703498e397e",
   "metadata": {},
   "source": [
    "## Improvements and Considerations\n",
    "\n",
    "Below are some considerations for our analysis.\n",
    "\n",
    "- Assumptions: If some assumptions are proven false, our results may be invalid or require further correction. \n",
    "- Overlooked Predictors & Relationships: There may be confounders, hidden interactions or other overlooked predictors excluded from the dataset or our model. For example, important variables could be the season, amenities, or neighbourhood crime rate. We also only briefly touched upon the moderately correlated numerical inputs.\n",
    "- Part vs. Whole: Only looking at the data for specific cities (Rome, Budapest and London) could result in *Simpson’s paradox*, where the apparent associations for these three cities are not observed in other cities, or in Europe, or the world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d480b1-141e-4358-9d30-1e3e00785f9a",
   "metadata": {},
   "source": [
    "## Future Research\n",
    "\n",
    "Future studies could examine the long-term trends in Airbnb price or consider more variables and interactions such as the season. However, it is important to note the risk of overfitting when including more predictors in a model. It may also be of interest to analyze Airbnb prices on a per-city basis, as well as the trends for different groupings of cities (ie. Capital cities), or the trends for other continents and countries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c3c0f-6022-470b-82f8-7bd8fa7ee74f",
   "metadata": {},
   "source": [
    "# 4) References\n",
    "\n",
    "- Toader, Victor, et al. \"Analysis of Price Determinants in the Case of Airbnb Listings.\" Economic Research-Ekonomska Istraživanja, vol. 35, no. 1, 2021, pp. 2493–2509. https://doi.org/10.1080/1331677x.2021.1962380.\n",
    "\n",
    "- Gyódi, Karol, and Łukasz Nawaro. \"Determinants of Airbnb Prices in European Cities: A Spatial Econometrics Approach.\" Tourism Management, vol. 86, 2021, https://doi.org/10.1016/j.tourman.2021.104319.\n",
    "\n",
    "- Gyódi, Karol, and Łukasz Nawaro. \"Airbnb Prices in European Cities.\" Kaggle, 10 Mar. 2024, www.kaggle.com/datasets/thedevastator/airbnb-prices-in-european-cities/data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99249632-1df4-4fb6-9bf7-e82268006b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
